{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pain Score evaluation Segment level (Select pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bsoid_kit import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extract with pose prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r'C:\\Users\\x\\Desktop\\final\\data\\old1_landmark7/'\n",
    "outpath = r'./data/test_output'\n",
    "landmarknum = 7\n",
    "framerate = 60\n",
    "embeder_path = ''#r'./data/model_embed/old_embed'\n",
    "clf_path = r'./data/model_clf/old_rf'\n",
    "\n",
    "files = os.listdir(root)\n",
    "if not os.path.isdir(outpath):\n",
    "    os.makedirs(outpath)\n",
    "for file in files:\n",
    "    filename = root+'/'+file\n",
    "    savename = (outpath+'/'+file).replace('.csv','')\n",
    "    if not os.path.isfile(embeder_path):\n",
    "        feat = bsoidfeat(filename,landmarknum,framerate,savename)\n",
    "    if os.path.isfile(embeder_path):\n",
    "        feat = bsoidfeat(filename,landmarknum,framerate)\n",
    "        embeder = joblib.load(embeder_path)\n",
    "        clf = joblib.load(clf_path)\n",
    "        embeddings = embeder.transform(feat)\n",
    "        motions = motion_predict(feat, embeder, clf)\n",
    "        joblib.dump([feat,embeddings,motions], savename)\n",
    "    elif os.path.isfile(clf_path):\n",
    "        feat = bsoidfeat(filename,landmarknum,framerate)\n",
    "        clf = joblib.load(clf_path)\n",
    "        motions = clf.predict(feat)\n",
    "        joblib.dump([feat,motions], savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pose analysis for Cap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r'./data/new_bsoidfeat/'\n",
    "files = os.listdir(root)\n",
    "posenum = 10\n",
    "\n",
    "poseB = [0]*posenum\n",
    "poseT = [0]*posenum\n",
    "for file in files:\n",
    "    if file.find('Cap')!=-1:\n",
    "        savfile = joblib.load(root+'/'+file)\n",
    "        labels = savfile[-1]\n",
    "        if file.find('basal')!=-1:\n",
    "            for i in range(posenum):\n",
    "                poseB[i]+= len(np.where(labels==i)[0])\n",
    "        if file.find('treat')!=-1:\n",
    "            for i in range(posenum):\n",
    "                poseT[i]+= len(np.where(labels==i)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.array(poseT)-np.array(poseB)\n",
    "sum2 = np.array(poseT)+np.array(poseB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00430005 0.03798376 0.01528906 0.02054467 0.00310559 0.16483516\n",
      " 0.00334448 0.10033445 0.04204491 0.60821787]\n",
      "[0.04307352 0.04816188 0.08772483 0.0271379  0.09778321 0.03455349\n",
      " 0.0542758  0.05119912 0.01475229 0.54133796]\n",
      "[False False False False False  True False  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(abs(diff)/sum(abs(diff)))\n",
    "print(np.array(sum2)/sum(sum2))\n",
    "print(abs(diff)/sum(abs(diff))>0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select pose to train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "posenum=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_pose(feat,labels,sel=None):\n",
    "    sel=np.arange(posenum)\n",
    "    # sel=[2,4,6,9]\n",
    "    sel_index = np.array([])\n",
    "    for s in sel:\n",
    "        sel_index = np.concatenate([sel_index, np.where(labels==s)[0]])\n",
    "    sel_index = sel_index.astype(int)\n",
    "    feat = feat[:,sel_index]\n",
    "    return feat.T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_basal_feats = []\n",
    "cap_treat_feats = []\n",
    "sng_basal_feats = []\n",
    "sng_treat_feats = []\n",
    "ro_basal_feats = []\n",
    "ro_treat_feats = []\n",
    "root = r'./data/old1_bsoidfeat/'\n",
    "files = os.listdir(root)\n",
    "for file in files:\n",
    "    [feat,labels] = joblib.load(root+file)\n",
    "    feat = np.array(feat)\n",
    "    labels = labels[0]\n",
    "    if file.find('Cap')!=-1:\n",
    "        if file.find('basal')!=-1:\n",
    "            cap_basal_feats.append(select_pose(feat,labels))\n",
    "        if file.find('treat')!=-1:\n",
    "            cap_treat_feats.append(select_pose(feat,labels))\n",
    "    elif file.find('pH5.2')!=-1:\n",
    "        if file.find('basal')!=-1:\n",
    "            sng_basal_feats.append(select_pose(feat,labels))\n",
    "        if file.find('treat')!=-1:\n",
    "            sng_treat_feats.append(select_pose(feat,labels))\n",
    "    else:\n",
    "        if file.find('basal')!=-1:\n",
    "            ro_basal_feats.append(select_pose(feat,labels))\n",
    "        if file.find('treat')!=-1:\n",
    "            ro_treat_feats.append(select_pose(feat,labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1556, 49)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap_basal_feats[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.zeros([0,49])\n",
    "y_train = []\n",
    "x_test = np.zeros([0,49])\n",
    "y_test = []\n",
    "bshuffles = []\n",
    "tshuffles = []\n",
    "for i in range(len(cap_basal_feats)):\n",
    "    #basal\n",
    "    feat = cap_basal_feats[i]\n",
    "    ##shuffle\n",
    "    ind = np.arange(len(feat))\n",
    "    np.random.shuffle(ind)\n",
    "    bshuffles.append(ind)\n",
    "    feat = feat[ind,:]\n",
    "    sp = len(feat)//2\n",
    "    x_train = np.concatenate([x_train,feat[:sp,:]])\n",
    "    y_train = y_train + [-1] * len(cap_basal_feats[i][:sp,:])\n",
    "    x_test = np.concatenate([x_test,cap_basal_feats[i][sp:,:]])\n",
    "    y_test = y_test + [-1] * len(cap_basal_feats[i][sp:,:])\n",
    "    feat = cap_treat_feats[i]\n",
    "    #treat\n",
    "    feat = cap_treat_feats[i]\n",
    "    ##shuffle\n",
    "    ind = np.arange(len(feat))\n",
    "    np.random.shuffle(ind)\n",
    "    tshuffles.append(ind)\n",
    "    feat = feat[ind,:]\n",
    "    sp = len(feat)//2\n",
    "    x_train = np.concatenate([x_train,feat[:sp,:]])\n",
    "    y_train = y_train + [1] * len(feat[:sp,:])\n",
    "    x_test = np.concatenate([x_test,feat[sp:,:]])\n",
    "    y_test = y_test + [1] * len(feat[sp:,:])\n",
    "# add RO\n",
    "train_split = 10 # 10%\n",
    "if train_split != 0:\n",
    "    for i in range(len(ro_basal_feats)):\n",
    "        sp = len(ro_basal_feats[i])//train_split\n",
    "        x_train = np.concatenate([x_train,ro_basal_feats[i][:sp,:]])\n",
    "        y_train = y_train + [-1] * len(ro_basal_feats[i][:sp,:])\n",
    "        x_test = np.concatenate([x_test,ro_basal_feats[i][sp:,:]])\n",
    "        y_test = y_test + [-1] * len(ro_basal_feats[i][sp:,:])\n",
    "        sp = len(ro_treat_feats[i])//train_split\n",
    "        x_train = np.concatenate([x_train,ro_treat_feats[i][:sp,:]])\n",
    "        y_train = y_train + [-1] * len(ro_treat_feats[i][:sp,:])\n",
    "        x_test = np.concatenate([x_test,ro_treat_feats[i][sp:,:]])\n",
    "        y_test = y_test + [-1] * len(ro_treat_feats[i][sp:,:])\n",
    "# add Sng\n",
    "train_split = 10 # 10%\n",
    "if train_split != 0:\n",
    "    for i in range(len(sng_basal_feats)):\n",
    "        sp = len(sng_basal_feats[i])//train_split\n",
    "        x_train = np.concatenate([x_train,sng_basal_feats[i][:sp,:]])\n",
    "        y_train = y_train + [-1] * len(sng_basal_feats[i][:sp,:])\n",
    "        x_test = np.concatenate([x_test,sng_basal_feats[i][sp:,:]])\n",
    "        y_test = y_test + [-1] * len(sng_basal_feats[i][sp:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier(n_estimators=20,max_depth=20)\n",
    "model = SVC(kernel='rbf', C=1000)\n",
    "model = model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Accuracy = ', model.score(x_train,y_train))\n",
    "# print('Accuracy = ', model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on control group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.08920641050395829\n",
      "Accuracy =  0.741994932043308\n",
      "Accuracy =  0.1247104247104247\n",
      "Accuracy =  0.6849252013808976\n",
      "Accuracy =  0.14216867469879518\n",
      "Accuracy =  0.37731958762886597\n",
      "Accuracy =  0.19372234513274336\n",
      "Accuracy =  0.4069492703266157\n"
     ]
    }
   ],
   "source": [
    "# Cap train\n",
    "x_train = np.zeros([0,49])\n",
    "y_train = []\n",
    "for i in range(len(cap_basal_feats)):\n",
    "    feat = cap_basal_feats[i]\n",
    "    feat = feat[bshuffles[i]]\n",
    "    sp = len(feat)//2\n",
    "    x_train = np.concatenate([x_train,feat[:sp,:]])\n",
    "    y_train = y_train + [1] * len(feat[:sp,:])\n",
    "print('Accuracy = ', model.score(x_train,y_train))\n",
    "x_train = np.zeros([0,49])\n",
    "y_train = []\n",
    "for i in range(len(cap_treat_feats)):\n",
    "    feat = cap_treat_feats[i]\n",
    "    feat = feat[tshuffles[i]]\n",
    "    sp = len(feat)//2\n",
    "    x_train = np.concatenate([x_train,feat[:sp,:]])\n",
    "    y_train = y_train + [1] * len(feat[:sp,:])\n",
    "print('Accuracy = ', model.score(x_train,y_train))\n",
    "# Cap test\n",
    "x_test = np.zeros([0,49])\n",
    "y_test = []\n",
    "for i in range(len(cap_basal_feats)):\n",
    "    feat = cap_basal_feats[i]\n",
    "    feat = feat[bshuffles[i]]\n",
    "    sp = len(feat)//2\n",
    "    x_test = np.concatenate([x_test,feat[sp:,:]])\n",
    "    y_test = y_test + [1] * len(feat[sp:,:])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "x_test = np.zeros([0,49])\n",
    "y_test = []\n",
    "for i in range(len(cap_basal_feats)):\n",
    "    feat = cap_treat_feats[i]\n",
    "    feat = feat[tshuffles[i]]\n",
    "    sp = len(feat)//2\n",
    "    x_test = np.concatenate([x_test,feat[sp:,:]])\n",
    "    y_test = y_test + [1] * len(feat[sp:,:])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "# RO\n",
    "x_test = np.zeros([0,49])\n",
    "y_test = []\n",
    "for i in range(len(ro_basal_feats)):\n",
    "    x_test = np.concatenate([x_test,ro_basal_feats[i]])\n",
    "    y_test = y_test + [1] * len(ro_basal_feats[i])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "x_test = np.zeros([0,49])\n",
    "y_test = []\n",
    "for i in range(len(ro_basal_feats)):\n",
    "    x_test = np.concatenate([x_test,ro_treat_feats[i]])\n",
    "    y_test = y_test + [1] * len(ro_treat_feats[i])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "# Sng\n",
    "x_test = np.zeros([0,49])\n",
    "y_test = []\n",
    "for i in range(len(sng_basal_feats)):\n",
    "    x_test = np.concatenate([x_test,sng_basal_feats[i]])\n",
    "    y_test = y_test + [1] * len(sng_basal_feats[i])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "x_test = np.zeros([0,49])\n",
    "y_test = []\n",
    "for i in range(len(sng_basal_feats)):\n",
    "    x_test = np.concatenate([x_test,sng_treat_feats[i]])\n",
    "    y_test = y_test + [1] * len(sng_treat_feats[i])\n",
    "print('Accuracy = ', model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no pose select\n",
    "Accuracy =  0.1263572105224805\n",
    "Accuracy =  0.6791909960226792\n",
    "Accuracy =  0.17070861554147548\n",
    "Accuracy =  0.5318393234672304\n",
    "Accuracy =  0.15990138989246397\n",
    "Accuracy =  0.3845990666100976\n",
    "Accuracy =  0.16797344949180668\n",
    "Accuracy =  0.3458788268036823\n",
    "# with pose select\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inference on old control groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_basal_feats = []\n",
    "cap_treat_feats = []\n",
    "sng_basal_feats = []\n",
    "sng_treat_feats = []\n",
    "ro_basal_feats = []\n",
    "ro_treat_feats = []\n",
    "root = r'./feat_old/'\n",
    "files = os.listdir(root)\n",
    "for file in files:\n",
    "    [feat,labels] = joblib.load(root+file)\n",
    "    feat = np.array(feat)\n",
    "    labels = labels[0]\n",
    "    if file.find('Cap')!=-1:\n",
    "        if file.find('basal')!=-1:\n",
    "            cap_basal_feats.append(select_pose(feat,labels))\n",
    "        if file.find('treat')!=-1:\n",
    "            cap_treat_feats.append(select_pose(feat,labels))\n",
    "    elif file.find('pH5.2')!=-1:\n",
    "        if file.find('basal')!=-1:\n",
    "            sng_basal_feats.append(select_pose(feat,labels))\n",
    "        if file.find('treat')!=-1:\n",
    "            sng_treat_feats.append(select_pose(feat,labels))\n",
    "    else:\n",
    "        if file.find('basal')!=-1:\n",
    "            ro_basal_feats.append(select_pose(feat,labels))\n",
    "        if file.find('treat')!=-1:\n",
    "            ro_treat_feats.append(select_pose(feat,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.18498615860609022\n",
      "Accuracy =  0.7138666145120282\n",
      "Accuracy =  0.06795160382667417\n",
      "Accuracy =  0.1956452129362792\n",
      "Accuracy =  0.061069773971641164\n",
      "Accuracy =  0.2849978194505015\n",
      "Accuracy =  0.086532475617348\n",
      "Accuracy =  0.18620958317101674\n"
     ]
    }
   ],
   "source": [
    "# Cap train\n",
    "x_train = np.zeros([0,49])\n",
    "y_train = []\n",
    "for i in range(len(cap_basal_feats)):\n",
    "    sp = len(cap_basal_feats[i])//2\n",
    "    x_train = np.concatenate([x_train,cap_basal_feats[i][:sp,:]])\n",
    "    y_train = y_train + [-1] * len(cap_basal_feats[i][:sp,:])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "x_test = np.zeros([0,49])\n",
    "y_test = []\n",
    "for i in range(len(cap_basal_feats)):\n",
    "    sp = len(cap_treat_feats[i])//2\n",
    "    x_train = np.concatenate([x_train,cap_treat_feats[i][:sp,:]])\n",
    "    y_train = y_train + [1] * len(cap_treat_feats[i][:sp,:])\n",
    "print('Accuracy = ', model.score(x_train,y_train))\n",
    "# Cap test\n",
    "x_test = np.zeros([0,49])\n",
    "y_test = []\n",
    "for i in range(len(cap_basal_feats)):\n",
    "    x_test = np.concatenate([x_test,cap_basal_feats[i]])\n",
    "    y_test = y_test + [1] * len(cap_basal_feats[i])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "x_test = np.zeros([0,49])\n",
    "y_test = []\n",
    "for i in range(len(cap_basal_feats)):\n",
    "    x_test = np.concatenate([x_test,cap_treat_feats[i]])\n",
    "    y_test = y_test + [1] * len(cap_treat_feats[i])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "# RO\n",
    "x_test = np.zeros([0,49])\n",
    "y_test = []\n",
    "for i in range(len(ro_basal_feats)):\n",
    "    x_test = np.concatenate([x_test,ro_basal_feats[i]])\n",
    "    y_test = y_test + [1] * len(ro_basal_feats[i])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "x_test = np.zeros([0,49])\n",
    "y_test = []\n",
    "for i in range(len(ro_basal_feats)):\n",
    "    x_test = np.concatenate([x_test,ro_treat_feats[i]])\n",
    "    y_test = y_test + [1] * len(ro_treat_feats[i])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "# Sng\n",
    "x_test = np.zeros([0,49])\n",
    "y_test = []\n",
    "for i in range(len(sng_basal_feats)):\n",
    "    x_test = np.concatenate([x_test,sng_basal_feats[i]])\n",
    "    y_test = y_test + [1] * len(sng_basal_feats[i])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "x_test = np.zeros([0,49])\n",
    "y_test = []\n",
    "for i in range(len(sng_basal_feats)):\n",
    "    x_test = np.concatenate([x_test,sng_treat_feats[i]])\n",
    "    y_test = y_test + [1] * len(sng_treat_feats[i])\n",
    "print('Accuracy = ', model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab4fce4da36998e8a3784a3b1ea772373c07eedc86da55b2021be344f3473b8a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('bsoid')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "976dc5bfe42cd6b3a847082a666c7c18191e37230973744f3d521e66da3262a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
