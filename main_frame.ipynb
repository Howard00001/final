{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pain Score evaluation Frame level (Select pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from feature_process import *\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_pose(feat,labels, sel=None, window=6):\n",
    "    sel=np.arange(10)\n",
    "    # sel=[1,5,7,8,9]\n",
    "    # sel=[2,4,6,9]\n",
    "    newfeat = []\n",
    "    for i in range(len(labels)*window):\n",
    "        f = feat[i,:]\n",
    "        if labels[i//window] in sel:\n",
    "            newfeat.append(f)\n",
    "    return np.array(newfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_basal_feats = []\n",
    "cap_treat_feats = []\n",
    "sng_basal_feats = []\n",
    "sng_treat_feats = []\n",
    "ro_basal_feats = []\n",
    "ro_treat_feats = []\n",
    "root = r'C:\\Users\\x\\Desktop\\final\\data/old1_landmark7/'\n",
    "poseroot = r'C:\\Users\\x\\Desktop\\final\\data\\old1_bsoidfeat/'\n",
    "files = os.listdir(root)\n",
    "posefiles = os.listdir(poseroot)\n",
    "for i in range(len(files)):\n",
    "    file = files[i]\n",
    "    dlc1 = dlc(root+file, True, 7)\n",
    "    feat = count_dist(dlc1.raw) # feature from landmark 7 \n",
    "    # feat = combine_feat(dlc1, sel_dist=[[0,3],[3,4],[1,2]], sel_ang=[[0,1,3],[1,3,4]], sel_coord=[], normalize=[0,1])\n",
    "    posefile = posefiles[i]\n",
    "    [posefeat,labels] = joblib.load(poseroot+posefile)\n",
    "    labels = labels[0]\n",
    "    if file.find('Cap')!=-1:\n",
    "        if file.find('basal')!=-1:\n",
    "            cap_basal_feats.append(select_pose(feat,labels))\n",
    "        if file.find('treat')!=-1:\n",
    "            cap_treat_feats.append(select_pose(feat,labels))\n",
    "    elif file.find('pH5.2')!=-1:\n",
    "        if file.find('basal')!=-1:\n",
    "            sng_basal_feats.append(select_pose(feat,labels))\n",
    "        if file.find('treat')!=-1:\n",
    "            sng_treat_feats.append(select_pose(feat,labels))\n",
    "    else:\n",
    "        if file.find('basal')!=-1:\n",
    "            ro_basal_feats.append(select_pose(feat,labels))\n",
    "        if file.find('treat')!=-1:\n",
    "            ro_treat_feats.append(select_pose(feat,labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "featnum = 8\n",
    "x_train = np.zeros([0,featnum])\n",
    "y_train = []\n",
    "x_test = np.zeros([0,featnum])\n",
    "y_test = []\n",
    "bshuffles = []\n",
    "tshuffles = []\n",
    "for i in range(len(cap_basal_feats)):\n",
    "    #basal\n",
    "    feat = cap_basal_feats[i]\n",
    "    ##shuffle\n",
    "    ind = np.arange(len(feat))\n",
    "    np.random.shuffle(ind)\n",
    "    bshuffles.append(ind)\n",
    "    feat = feat[ind,:]\n",
    "    sp = len(feat)//2\n",
    "    x_train = np.concatenate([x_train,feat[:sp,:]])\n",
    "    y_train = y_train + [-1] * len(cap_basal_feats[i][:sp,:])\n",
    "    x_test = np.concatenate([x_test,cap_basal_feats[i][sp:,:]])\n",
    "    y_test = y_test + [-1] * len(cap_basal_feats[i][sp:,:])\n",
    "    feat = cap_treat_feats[i]\n",
    "    #treat\n",
    "    feat = cap_treat_feats[i]\n",
    "    ##shuffle\n",
    "    ind = np.arange(len(feat))\n",
    "    np.random.shuffle(ind)\n",
    "    tshuffles.append(ind)\n",
    "    feat = feat[ind,:]\n",
    "    sp = len(feat)//2\n",
    "    x_train = np.concatenate([x_train,feat[:sp,:]])\n",
    "    y_train = y_train + [1] * len(feat[:sp,:])\n",
    "    x_test = np.concatenate([x_test,feat[sp:,:]])\n",
    "    y_test = y_test + [1] * len(feat[sp:,:])\n",
    "# add RO\n",
    "train_split = 10 # 10%\n",
    "if train_split != 0:\n",
    "    for i in range(len(ro_basal_feats)):\n",
    "        sp = len(ro_basal_feats[i])//train_split\n",
    "        x_train = np.concatenate([x_train,ro_basal_feats[i][:sp,:]])\n",
    "        y_train = y_train + [-1] * len(ro_basal_feats[i][:sp,:])\n",
    "        x_test = np.concatenate([x_test,ro_basal_feats[i][sp:,:]])\n",
    "        y_test = y_test + [-1] * len(ro_basal_feats[i][sp:,:])\n",
    "        sp = len(ro_treat_feats[i])//train_split\n",
    "        x_train = np.concatenate([x_train,ro_treat_feats[i][:sp,:]])\n",
    "        y_train = y_train + [-1] * len(ro_treat_feats[i][:sp,:])\n",
    "        x_test = np.concatenate([x_test,ro_treat_feats[i][sp:,:]])\n",
    "        y_test = y_test + [-1] * len(ro_treat_feats[i][sp:,:])\n",
    "# add Sng\n",
    "train_split = 10 # 10%\n",
    "if train_split != 0:\n",
    "    for i in range(len(sng_basal_feats)):\n",
    "        sp = len(sng_basal_feats[i])//train_split\n",
    "        x_train = np.concatenate([x_train,sng_basal_feats[i][:sp,:]])\n",
    "        y_train = y_train + [-1] * len(sng_basal_feats[i][:sp,:])\n",
    "        x_test = np.concatenate([x_test,sng_basal_feats[i][sp:,:]])\n",
    "        y_test = y_test + [-1] * len(sng_basal_feats[i][sp:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='rbf', C=1000)\n",
    "model = model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.09083888406216817\n",
      "Accuracy =  0.735973597359736\n",
      "Accuracy =  0.0990121311580912\n",
      "Accuracy =  0.7334024100084428\n",
      "Accuracy =  0.15332998661311914\n",
      "Accuracy =  0.30163230240549826\n",
      "Accuracy =  0.1945289454277286\n",
      "Accuracy =  0.36365531619179986\n"
     ]
    }
   ],
   "source": [
    "# Cap train\n",
    "x_train = np.zeros([0,featnum])\n",
    "y_train = []\n",
    "for i in range(len(cap_basal_feats)):\n",
    "    feat = cap_basal_feats[i]\n",
    "    feat = feat[bshuffles[i]]\n",
    "    sp = len(feat)//2\n",
    "    x_train = np.concatenate([x_train,feat[:sp,:]])\n",
    "    y_train = y_train + [1] * len(feat[:sp,:])\n",
    "print('Accuracy = ', model.score(x_train,y_train))\n",
    "x_train = np.zeros([0,featnum])\n",
    "y_train = []\n",
    "for i in range(len(cap_treat_feats)):\n",
    "    feat = cap_treat_feats[i]\n",
    "    feat = feat[tshuffles[i]]\n",
    "    sp = len(feat)//2\n",
    "    x_train = np.concatenate([x_train,feat[:sp,:]])\n",
    "    y_train = y_train + [1] * len(feat[:sp,:])\n",
    "print('Accuracy = ', model.score(x_train,y_train))\n",
    "# Cap test\n",
    "x_test = np.zeros([0,featnum])\n",
    "y_test = []\n",
    "for i in range(len(cap_basal_feats)):\n",
    "    feat = cap_basal_feats[i]\n",
    "    feat = feat[bshuffles[i]]\n",
    "    sp = len(feat)//2\n",
    "    x_test = np.concatenate([x_test,feat[sp:,:]])\n",
    "    y_test = y_test + [1] * len(feat[sp:,:])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "x_test = np.zeros([0,featnum])\n",
    "y_test = []\n",
    "for i in range(len(cap_basal_feats)):\n",
    "    feat = cap_treat_feats[i]\n",
    "    feat = feat[tshuffles[i]]\n",
    "    sp = len(feat)//2\n",
    "    x_test = np.concatenate([x_test,feat[sp:,:]])\n",
    "    y_test = y_test + [1] * len(feat[sp:,:])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "# RO\n",
    "x_test = np.zeros([0,featnum])\n",
    "y_test = []\n",
    "for i in range(len(ro_basal_feats)):\n",
    "    x_test = np.concatenate([x_test,ro_basal_feats[i]])\n",
    "    y_test = y_test + [1] * len(ro_basal_feats[i])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "x_test = np.zeros([0,featnum])\n",
    "y_test = []\n",
    "for i in range(len(ro_basal_feats)):\n",
    "    x_test = np.concatenate([x_test,ro_treat_feats[i]])\n",
    "    y_test = y_test + [1] * len(ro_treat_feats[i])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "# Sng\n",
    "x_test = np.zeros([0,featnum])\n",
    "y_test = []\n",
    "for i in range(len(sng_basal_feats)):\n",
    "    x_test = np.concatenate([x_test,sng_basal_feats[i]])\n",
    "    y_test = y_test + [1] * len(sng_basal_feats[i])\n",
    "print('Accuracy = ', model.score(x_test,y_test))\n",
    "x_test = np.zeros([0,featnum])\n",
    "y_test = []\n",
    "for i in range(len(sng_basal_feats)):\n",
    "    x_test = np.concatenate([x_test,sng_treat_feats[i]])\n",
    "    y_test = y_test + [1] * len(sng_treat_feats[i])\n",
    "print('Accuracy = ', model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab4fce4da36998e8a3784a3b1ea772373c07eedc86da55b2021be344f3473b8a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('bsoid')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
